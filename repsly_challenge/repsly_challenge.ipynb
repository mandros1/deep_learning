{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Repsly trial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data (this might take a minute or so)...done.\n"
     ]
    }
   ],
   "source": [
    "from repsly_data import RepslyData\n",
    "\n",
    "repsly_data = RepslyData()\n",
    "print('Reading data (this might take a minute or so)...', end='')\n",
    "repsly_data.read_data('data/trial_users_analysis.csv', mode='FC')\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's see what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X[20, 241]: [[303   1   0 ...,   0   0   0]\n",
      " [192   4   4 ...,   0   0   0]\n",
      " [363   0   0 ...,   0   0   0]\n",
      " ..., \n",
      " [180   0   0 ...,   0   0   0]\n",
      " [336   0   0 ...,   0   0   0]\n",
      " [459   2   1 ...,   0   0   0]]\n",
      "y: [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "read_batch = repsly_data.read_batch(batch_size=20)\n",
    "\n",
    "X, y = next(read_batch)\n",
    "print('X{}: {}'.format(list(X.shape), X))\n",
    "print('y:', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, each input vector `X` has `1+15*16=241` values, most of which are zeros. The first one is the trial start date as offset from `2016-01-01` and the rest is different usage parameters for the following `16` days. Data provided by batch read is randomly shuffled. Output values are stored in `y` and they represent if the user purchased the Repsly service after the trial or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Ensamble class for training and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from repsly_nn import RepslyFC\n",
    "from ensamble import Ensamble\n",
    "\n",
    "ens = Ensamble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepslyFC/no_of_layers-6/hidden_size-369/use_batch_norm-True/keep_prob-0.6/input_keep_prob-0.76/batch_norm_decay-0.99/lr-0.001/dr-0.99/ds-20\n",
      "RepslyFC/no_of_layers-7/hidden_size-223/use_batch_norm-True/keep_prob-0.67/input_keep_prob-0.66/batch_norm_decay-0.99/lr-0.001/dr-0.99/ds-20\n",
      "RepslyFC/no_of_layers-6/hidden_size-258/use_batch_norm-True/keep_prob-0.38/input_keep_prob-0.78/batch_norm_decay-0.99/lr-0.001/dr-0.99/ds-20\n",
      "RepslyFC/no_of_layers-5/hidden_size-300/use_batch_norm-True/keep_prob-0.6/input_keep_prob-0.88/batch_norm_decay-0.99/lr-0.001/dr-0.99/ds-20\n",
      "RepslyFC/no_of_layers-6/hidden_size-177/use_batch_norm-True/keep_prob-0.42/input_keep_prob-0.81/batch_norm_decay-0.99/lr-0.001/dr-0.99/ds-20\n",
      "################################################################################\n",
      "Checkpoint directory is: /Users/davor/projects/deep_learning/repsly_challenge/checkpoints/RepslyFC/no_of_layers-6/hidden_size-369/use_batch_norm-True/keep_prob-0.6/input_keep_prob-0.76/batch_norm_decay-0.99/lr-0.001/dr-0.99/ds-20\n",
      "Creating tf.train.Saver()...done\n",
      "self.checkpoint_path: checkpoints/RepslyFC/no_of_layers-6/hidden_size-369/use_batch_norm-True/keep_prob-0.6/input_keep_prob-0.76/batch_norm_decay-0.99/lr-0.001/dr-0.99/ds-20\n",
      "ckpt: None\n",
      "[00000/10.9 sec]   train/validation loss = 1.80806/1.79926\n",
      "[00020/32.2 sec]   train/validation loss = 0.41289/0.43696\n",
      "[00040/49.5 sec]   train/validation loss = 1.79510/1.79061\n",
      "[00060/65.6 sec]   train/validation loss = 0.40281/0.33812\n",
      "[00080/88.2 sec]   train/validation loss = 0.35451/0.31067\n",
      "[00100/109.8 sec]   train/validation loss = 0.22204/0.26039\n",
      "[00120/128.0 sec]   train/validation loss = 0.19640/0.23609\n",
      "[00140/148.4 sec]   train/validation loss = 0.21757/0.21733\n",
      "[00160/167.4 sec]   train/validation loss = 0.22895/0.21833\n",
      "[00180/189.4 sec]   train/validation loss = 0.25821/0.21781\n",
      "[00200/208.9 sec]   train/validation loss = 0.20233/0.22550\n",
      "[00220/230.8 sec]   train/validation loss = 0.19859/0.18983\n",
      "[00240/252.7 sec]   train/validation loss = 0.20532/0.20714\n",
      "[00260/276.0 sec]   train/validation loss = 0.21613/0.18452\n",
      "[00280/294.7 sec]   train/validation loss = 0.24357/0.20729\n",
      "[00300/309.6 sec]   train/validation loss = 0.20426/0.20366\n",
      "[00320/328.3 sec]   train/validation loss = 0.28317/0.22654\n",
      "[00340/350.3 sec]   train/validation loss = 0.13050/0.18250\n",
      "[00360/369.4 sec]   train/validation loss = 0.26928/0.26514\n",
      "[00380/388.4 sec]   train/validation loss = 0.24395/0.21028\n",
      "[00400/407.0 sec]   train/validation loss = 0.19751/0.19291\n",
      "[00420/422.5 sec]   train/validation loss = 0.14170/0.20070\n",
      "[00440/437.9 sec]   train/validation loss = 0.15237/0.17615\n",
      "[00460/454.7 sec]   train/validation loss = 0.18899/0.19601\n",
      "[00480/468.9 sec]   train/validation loss = 0.17131/0.18615\n",
      "[00500/483.6 sec]   train/validation loss = 0.18840/0.18225\n",
      "[00520/501.8 sec]   train/validation loss = 0.17712/0.20535\n",
      "[00540/524.4 sec]   train/validation loss = 0.19652/0.18366\n",
      "[00560/541.1 sec]   train/validation loss = 0.22510/0.20119\n",
      "[00580/559.5 sec]   train/validation loss = 0.14687/0.17032\n",
      "[00600/584.8 sec]   train/validation loss = 0.18870/0.18560\n",
      "[00620/602.2 sec]   train/validation loss = 0.23570/0.20329\n",
      "[00640/618.7 sec]   train/validation loss = 0.19642/0.16872\n",
      "[00660/637.4 sec]   train/validation loss = 0.17623/0.16670\n",
      "[00680/655.4 sec]   train/validation loss = 0.20053/0.19727\n",
      "[00700/678.0 sec]   train/validation loss = 0.19965/0.17828\n",
      "[00720/702.3 sec]   train/validation loss = 0.15761/0.19371\n",
      "[00740/730.0 sec]   train/validation loss = 0.21743/0.18296\n",
      "[00760/755.7 sec]   train/validation loss = 0.25719/0.23858\n",
      "[00780/780.9 sec]   train/validation loss = 0.38367/0.22518\n",
      "[00800/800.4 sec]   train/validation loss = 0.17695/0.19905\n",
      "[00820/819.3 sec]   train/validation loss = 0.20390/0.20982\n",
      "[00840/839.4 sec]   train/validation loss = 0.20490/0.17948\n",
      "[00860/860.2 sec]   train/validation loss = 0.20944/0.19671\n",
      "[00880/875.7 sec]   train/validation loss = 0.20790/0.19281\n",
      "[00900/897.7 sec]   train/validation loss = 0.19695/0.16113\n",
      "[00920/912.9 sec]   train/validation loss = 0.16843/0.18981\n",
      "[00940/941.7 sec]   train/validation loss = 0.13220/0.18786\n",
      "[00960/957.2 sec]   train/validation loss = 0.15063/0.17408\n",
      "[00980/974.6 sec]   train/validation loss = 0.16820/0.18157\n",
      "[01000/989.6 sec]   train/validation loss = 0.13269/0.17949\n",
      "[01020/1014.0 sec]   train/validation loss = 0.17813/0.17018\n",
      "[01040/1032.7 sec]   train/validation loss = 0.13059/0.19124\n",
      "[01060/1051.0 sec]   train/validation loss = 0.19591/0.19641\n",
      "[01080/1070.2 sec]   train/validation loss = 0.17203/0.17342\n",
      "{'loss': 0.1995934322476387, 'accuracy': 0.93073640046296302, 'precision': 0.85365853658536583, 'recall': 0.54000000000000004, 'f1_score': 0.65201465201465203}\n",
      "################################################################################\n",
      "Checkpoint directory is: /Users/davor/projects/deep_learning/repsly_challenge/checkpoints/RepslyFC/no_of_layers-7/hidden_size-223/use_batch_norm-True/keep_prob-0.67/input_keep_prob-0.66/batch_norm_decay-0.99/lr-0.001/dr-0.99/ds-20\n",
      "Creating tf.train.Saver()...done\n",
      "self.checkpoint_path: checkpoints/RepslyFC/no_of_layers-7/hidden_size-223/use_batch_norm-True/keep_prob-0.67/input_keep_prob-0.66/batch_norm_decay-0.99/lr-0.001/dr-0.99/ds-20\n",
      "ckpt: None\n",
      "[00000/10.3 sec]   train/validation loss = 0.38697/0.40738\n",
      "[00020/25.8 sec]   train/validation loss = 0.59531/0.58612\n",
      "[00040/40.3 sec]   train/validation loss = 0.38902/0.39318\n",
      "[00060/51.6 sec]   train/validation loss = 0.31117/0.33474\n",
      "[00080/65.1 sec]   train/validation loss = 0.28537/0.28010\n",
      "[00100/77.3 sec]   train/validation loss = 0.27862/0.29307\n",
      "[00120/89.7 sec]   train/validation loss = 0.36535/0.27595\n",
      "[00140/102.3 sec]   train/validation loss = 0.27698/0.27041\n",
      "[00160/115.3 sec]   train/validation loss = 0.22580/0.23326\n",
      "[00180/128.5 sec]   train/validation loss = 0.23595/0.22669\n",
      "[00200/143.5 sec]   train/validation loss = 0.29238/0.24215\n",
      "[00220/158.7 sec]   train/validation loss = 0.26148/0.20338\n",
      "[00240/171.6 sec]   train/validation loss = 0.26188/0.20132\n",
      "[00260/185.1 sec]   train/validation loss = 0.21726/0.19744\n",
      "[00280/196.7 sec]   train/validation loss = 0.15285/0.22906\n",
      "[00300/207.5 sec]   train/validation loss = 0.23128/0.20053\n",
      "[00320/217.8 sec]   train/validation loss = 0.25175/0.21205\n",
      "[00340/235.0 sec]   train/validation loss = 0.10995/0.25428\n",
      "[00360/247.5 sec]   train/validation loss = 0.26217/0.22382\n",
      "[00380/258.8 sec]   train/validation loss = 0.26035/0.23051\n",
      "[00400/270.7 sec]   train/validation loss = 0.19929/0.21379\n",
      "[00420/285.8 sec]   train/validation loss = 0.27651/0.20912\n"
     ]
    }
   ],
   "source": [
    "arch = {\n",
    "        'no_of_layers': {'lin': (4, 8)},\n",
    "        'hidden_size': {'lin': (128, 384)},\n",
    "        'use_batch_norm': 'True',\n",
    "        'keep_prob': {'lin': (0.3, 0.70, 2)},\n",
    "        'input_keep_prob': {'lin': (0.65, 0.95, 2)},\n",
    "        'batch_norm_decay': 0.99 # {'inv-log': (0.9, 0.99, 2)},\n",
    "}\n",
    "learning_dict = {\n",
    "    'learning_rate': 0.001,\n",
    "    'decay_steps': 20,\n",
    "    'decay_rate': 0.99 #{'inv-log': (0.99, 0.999, 3)}\n",
    "}\n",
    "train_dict = {\n",
    "    'batch_size': 512,\n",
    "    'epochs': 100,\n",
    "    'skip_steps': 20\n",
    "}\n",
    "key='f1_score'\n",
    "\n",
    "no_of_nets = 5\n",
    "no_of_loops = 50\n",
    "\n",
    "for _ in range(no_of_loops):\n",
    "    ens.add_nets(RepslyFC, arch=arch, data=repsly_data, learning_dict=learning_dict, no_of_nets=no_of_nets)\n",
    "    ens.train_untrained(train_dict)\n",
    "    ens.print_stat_by_key('f1_score')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the best candidates a little bit more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_of_top_nets = 0\n",
    "no_of_loops = 0\n",
    "\n",
    "for _ in range(no_of_loops):\n",
    "    ens.train_top_nets_by_key_stat(key, no_of_top_nets, train_dict)\n",
    "    ens.print_stat_by_key('f1_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ens.print_stat_by_key('f1_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ens.print_stat_by_key('loss', reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arch = {\n",
    "        'no_of_layers': 6,\n",
    "        'hidden_size': 256,\n",
    "        'use_batch_norm': 'True',\n",
    "        'keep_prob': 0.68,\n",
    "        'input_keep_prob': 0.72,\n",
    "        'batch_norm_decay': 0.99\n",
    "}\n",
    "learning_dict = {\n",
    "    'learning_rate': 0.001,\n",
    "    'decay_steps': 20,\n",
    "    'decay_rate': 0.99\n",
    "}\n",
    "train_dict = {\n",
    "    'batch_size': 512,\n",
    "    'epochs': 100,\n",
    "    'skip_steps': 20\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
